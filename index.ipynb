{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Final Project - Facial Expression Classification with PyTorch'\n",
    "author: \"Euibin Kim, Yuanting Pan, Lei Xu\"\n",
    "date: \"2023-03-24\"\n",
    "categories: [week 10, Project, Python]\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjepFMdPZM8N"
   },
   "source": [
    "We developed a model that finds facial expressions (happy, sad, surprise, disgust, neutral, fear, and angry) from image input using a PyTorch package.\n",
    "In this blog post, we will focus on important technical details of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U690tOxXS4C2"
   },
   "source": [
    "## 1. Finetuning ResNet, Image Augmentation\n",
    "\n",
    "Instead of implementing everything from scratch, we decided to finetune ResNet50.<br>\n",
    "First, we began by writing a class `Resnet`."
   ]
  },
  {
   "attachments": {
    "resnet.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAB7CAMAAAB6t7bCAAABv1BMVEX///+6yNOx3fDV6NQAAADjyADa6Pxth2T/8sz4zsz6aAD19fUboeK9y9aPoK7t7e3n5+dVVVWtra2mpqa55/nfOwDW3OfbdADUvgDtzwA/XUFRZ3pzh5dPan/5ztLfw3fJ4MeIq8LCyc+Io8u80JaGl6Z8pL3R1tqRssfNkI6i0ud9j55AXzWyzqKz3/KFkp0AltqswNdmmcSGu9XH1uLJycnd3d2jr7lwcHBJSUnN0cuVoJPm4MZzfIPMvohzc3ODg4OXl5fQtABTb0nw3ae41bDZlIhhYWG/v7/ozs22yufoTQDiqKXjzpr/cACBgYE2NjZYbnYmJiY9PT1PT08UFBT//9sqKiqWu8VfdoLiYgB+nqe/ybyruKdddHZCOgC2UACijwBCU1jIVQB9k3Z7bQCBbm3PyK4Adrx8e2vJ+/9dVVTr1Mbw397o6NMrTiskShM1UmlJIgAyFgChRgBYKQAiEgBRTUGuqpZ7d2mbi4o7Ny2cmIaCOQDYt7VWKgAuKB+TgH+3ogAAaa5sXwB3jm9pXFtZTwDa0rY+HAAzf7cvKQBHbpNSgp+waWankwAXFwBqLQCPQADWp4jQ0aPuM34eAAAYfUlEQVR4nO2djX/b5nHHHym31DZM4Y1V49Vel6SNWrohk0wAQVscgWgbkL2YEEEEsii5ivweL90W27Hi2G7sJo6Trmvs7Q/ePQBJPAAeEJDsunKM+4SMTP0IUs+Xd8899xxAQiqrrLLKKqvsJTWdWvohvFuSmEcENPq/6F9LukBFIvP7pfEPkj55QGCPOP6nzh6zsiIDap3EQzJoRABr/C/bIRpKXKLjnRA9RSUigBI/Q4PxoJsQ/d+APnvEJQiR+TaxLPZx4hjP7A/54ZlvC4KKIyc4dPQkBz//NuAAUzSaI4SMFHtJ0wj0hEGPPgXAJg6AgwKNstI1ikagT52gAZ/+oAkaYnFEpCpp+Fu8yR6JlETAQxILBKpBP12SJAlfvvKr2Hz83Cog6eBCDwfcxWG3B4FF0dgQgGgA6GbPon6iETOgT4EeENNGNC56k4bDiyBECZ9q4M/hQR1w8BcSyID+gwegR0dXCwwkakZK9EGwJQBZA5EMO2TQAccBj/XFl918GtAU0rEx6oi2K0gmsX38ESwdx8yzCQ6pByYYErpWNPKggNBRwVHooLoUoolPlXG09TEauUP8HqLpCToikns6fYUO8QxiDEmkRAlCUYHe04fcgSTgS6nwFx2NA2X+0HE8lwwoIQcnlYGK3kKGBlgOfcinIy9Sx9JhiZg+fQqosoP/dCgHdDhEhsPrhgeI0AhgOOgw1M8cCEMeauwQDd5HLxWYVGlN0QQ9fBo1Pf+9vmRGAxoO0ACnFonoRO+jAwB+4MHScJgFiXqNpdNPM37yDY8+BVTL84WIA/oLRjb0n06fHiBCo4RjrFE0dBZSFAbNkHih0jWIaIpjNPIYDU5fFZmp4dxCB1QBdQgYuVTkYodDjtONbCEXkAUPZ5c+zhoGHTuaIWhg4zgK0DFRMIQ+gKiAhY4SpQGuFx6YQiN+YEKExsO5Bg+yFCoFBUwX8JUdCTo2yGRg0LxO9d2/6GgcKFPpJ1WVMI21MPRYhok/quguqoaf6p5G81t0hh6dnVUjJEOsJUFdoq4kmT36iNXXVCE6gKZGArxzVMHCfEuwUCNaInEUojhEwiNFL+X08F7oW/iD4jj0d/QV1L/YQFRWWWWVVVZZZZVV9sKZpKVsXO9bTNnhD1g7/O8rKTuVtukrLC4n7Y20CXtXSs9OyWw1JO2TxF/8wW9Tf/BvX0nZb58xGVxmJMk443Lfe/+csHd//C8J+8n7KfuP1aT953Rw3vq7pP3XQtJ+KpZVnpiu3F8vUJ6d7OeQXxYoj7+RNzK/+teE/ewfkvbzt/8xaW8/czSikDBpjObNVxO2+OMjCfvJa3+VsGN//aOk/TpG00xY/ae1pB2fonl9PqVcTipP6nnKE6lj/iJG05itXMhHc5i1v/nZoaT9/G9TXvMioplPGKKZYy2BZraSQdNoJpQnUsoEmpnKCk2FpkJToanQVGheejQ6zZt1UqE5cGiIBS4EoFRoDh4a0yHEI0NSoTlwaAxDU8CxKzQHDo0g9IOOpiwVB7SNjY39oWmOb8Vo8pVpNLGyCE2+8sCjIaIkhVnAbDQbtHFlez9omqN6c/5svQSa5i+pslkCTXO93mxGygI0kfI5oRGEvCMmTOvwHsygoQ2RAMVotj89s8+AVt85O4K1UmjW1kaww1Wm0ZzbGYFXL4Pm3M46uFyIzxqNPnADd/IXTbvmI2Mb6vloBlk0skZKrWuu37hxY2MfaJr1+hqs10sENFSezVMm0aDyOKx/XCKgofJknvIZoxFpx6E26QjV7cQRDdYpEI2pdkAjthUEEoWiOCrIGTSqieuaYjTn4dNPvz2/dzTNEfgDGH/CZ6JprofKoNhrxkq/2GvGSngWXvNhaPlozLB5qq9oFiG24PqKZbngkL5OJEPzA8ZtEE3PJLpHOyEdvEc0Ckk0xY2T58Fg4JeYa26eOXNmHwGt2VgPjTuDJNHMUibRsMrZaGYp94jGp63wt/LReOFbVEytT4gr6gbmvkQAYiMaRJHymt4SkUIoeIvQBBk00TAWe80GXL/+WX4asKmfOnVK3+IFtGYj+HgnPeC1LJpQWV/jK1MBrdlw62dHqQGvcQIaJmdu8zhfuUc0t3YfXb3z+W4umo6WQGOHQcxYMrhojCQalYPGkU2/nNdso+XPNVub1Hho5uvBqL4OiQGv1docNJgwHE8pa6isZdGg8hzGKpoUTwa8Nre8UOOhWaPKBk85G83tsJnan6JZgUMfXv5i904uGsuk97ajmeXRqETpUDSukk0DRF3SdX2pxFxzvSBDW93avLDKReNj/soMeA3m2mDXeGiC9Xo9GvBYKfPRUGU84DVot/0OD019Z5RQLvvt9sAtgSbqiIi95sOrSOqyv5KfodHzdawB0WQiAUXTkzE1IIZDrE4yDdD7tFVY7JPAhI5AFPBUhxis21A0umlRK/aaI5/dnZ2hiYJOuF6DH1qAeLWCfgDQ4gW0SBmn2awys66ZKk+klJl1DSp3kspuyYDmgn+PSQNWVqIsIA+NYEB47qINPUsQQOmbvo/O4Q8Uk57fwHkdP+8NhGj6vYEpe2XSgMePfzcjQ7tAVlcviKvcakB9fX6aEtdaRleGbovnNTOUmWrAVIkDXlswuvZEmakGcJTdMl5z2Lt07zbEXnPnyy+/v7qXakDCU7iWe+5VlKHZ+KcEYon9mvPbMwMa2bpwSud6TQM/t9PJvdaybcOw+WgamAWNuMo0mgamxKOJL4yVXS6a+YBVLjDKIjSA4QyYuWZ3d/fyXtDYhWhyLULTlx16AmoKTXsujQbgOswKaFu46PqaO9d4J+dHwISpudYyP6DVd87OM2kAq8ymAQ0mDcBsYarMpAFrKWV3oixCcwkuDa7FAe2LybLm+dXQrKGhZ9C0MCLPJQo1uK55cpdBcwwtkQZ8fTqnUAMNOrkzaUB3OTC4acAglQYM7GXX5qYBXioNcOXlzpCfBqBywCi9zrLslfKaw7fv32aSZ5qwff7nQ7PI1t8oGsmhfYIOJ0OrtVxoMxnaZxtHHt+I0Ty4iMaioT2bp/nlTdhJ1NBguTbnL/PSAKpkamg1VOKNlwag0mdqaFS5HCmzacCOH8TK5VBZDs39a5cYNJfRHu0ZzXK5iicKf7+YRKO5HfD8gJMGzHUDFs2RxwDfMnPNg6+++goYNF8TTJ8l7pKzvj5iK2O1wDOiJCmz5EwrPdfweV4TKkfTyR1/3wmMgc3xGlQ2kkp5YATDUmgeerevuRM0u5evou3uGc27V3Lbd1No3rlSS6CJdjnd4oB25MzGBluoofHsmwfFaJrrZ6kdZxeSrS5vrhkr2U2B2lSZqqGtxcoTKWWqUDNDWZgGHD78CU0FQjR3KJrP94HmnSvLJdEcvfJ6Eo1t6hpkMrR2TWDTgDPh0pjdrwm9hkGzuonPvMBDcy40Fo3d6XLRZJXGRJlCwyhPTJVzPDRZZXeiLEJz7drthwGzrnn06NHKPtAcvfJuSTRH33mPRSNIMvhOJqC1u9TigHb+/Pkb8O1Gcq55cIxZ11z4+kLOpsB8vZEIU77c4qYBWWUgt3LSgFg5mdxbHj8NSCs7XqtTMg24FDz8IFHe3Eca8C474kVojr7zncigIaIoZgs1lm30BtBiAtpd2E5Vno/95rW4hobP41ee5wHOMquVGWlA04dzbN0gPw2oD2CNrQawyiSauptSlk8Dbg9vf8KUN1cglTyfDv8rgwZHvDgZCNEcPRqFv/F+Td4up+3PxXPNDbiZ6Q04BjEafXNV2OLv13h1WF8fsHmX0fI4NbTmeoDKBjBK3251ODW05rqPynlg0AR2S+bU0DA/q/ujJqv05JZcpoZ2D+7DbQbNh7d2ExlaAK+8AsNyaHDEx+nX8rt59mYkjMJfhGYoyUTOommBSoT0XBMnzzQLYNFIW7/WT69y0ax9DI0Gi2ZOdg3eXDPa+dhPokGlzZ1rdj52k2jm7MDmzTXr7sc7v6zzlQWV54eHb19K7Nf4PsSFmk2gTCAKbW/nj/h77IgT8t47uXZ0bDT8RWh6Vk/1pTQaAwbBwGcDWrLZ6Q+/QWO9RhAR7yYPjX8Odnbivcv2QpsaDw1Qpc9Vpnc5UbkWD/hYyfWac36esgDNtXv3H95LljcPxQFtyw/RbEZoSoz4lTfDsT1abO98R5QQjWBJw2zluW2p7bY1l4vm4sWPPvqIWXJubW5ubW1ylpyY6FKbdtTU7ND/OGnARDmtoXVDJScNSChPTJUyB00jVK6llJ197Nd8eBWuykzyDPbWluyPA9p75Ua8HJqjR787iWiIYtMrhXCqAa211uKruWiOHXv/o/dfY6sBzAb0kkQEnd7eaobNGGhxd1ktPK9yEtDoVRrpRR7HDR65ypNLRNRFvAnjto2p8kRK+QtnfEj9ramyzlUuvCHpAqE3PbyR6Y23y7kCK5+vfMH0Bgzxw/DKHtAgm8WSaK78N90UAKtjkmxHzTJ43Q7UGDQb2+fZXc73AR4AH82qpRAJb7r1x0T75HgG6XQWwJ8bo1Hwg0EvxPjHeZ7SawNEypMO0SwNbzqve7Mmu6iMQt+CiTHAwonS+iNXGcTKNxxLIoolhjcV34U6fjf/w9uAhsv27q0pms2rr8QpdDk0dL4phebKohJuQBPN5qCxu8Krgikz+zXJJeexiw8uvnbxQQoNt/KMn9xmPOA1XPFBW+YVajJKD5V2FPpOTq/GONmvacYDXmsFLVgweIWajHKAym65Qk0KzWWAL1bYNGB4em9oaJZWQkjXNmENraOrtp5tdvLoanPOZcqbqY6aP/3hm4vwPrtfc2H11Clu5XlnZz0OUzW7hQuQ1hoPTTOpNLq4CGlxN6BROWrGG2RdqlzgbkDTZsKEchFq7XJLznuhTeeaXVzW3GHR2Ft7QROtbd59L8++GycM4fo0bNugUx1nXdMKcKLxulM0T27AkydPmIB27KNvvmGrAXTRqXO9prl+0gUmDeguQHuNuynQXB95jNKw29DucqsBzcZoB5jJPVRyqwFppdxGrymH5lqYCNyL0KyE/4jnmk047Rqnx37z9pvlRnyWTZacYR1t5llpMk1k4nXN45uPHz++GW9Av3/xwbEHH73GoDlFJIFTQ6Njst4CN5Whcb2GKv1BjCYvQwuVo8E0JR7nXVw0VBmklSXR3PvksPvBw7HXXP7i8uVokzNC43odzwtKLzkL62gRmnH1eSYasjy3TNgMbWPjCFMNgN/A95DYFJBoTw03oKHPMJWxZIaWQFPfgXMZ5XJ2XUMD2vSYJ1LKTECDtRxlEZqA9gbgsnPSG0AD2ozuzVloSlSfQzSTosFMNG4LgxrbtgHbGxB7DRz70zepXc68NKDZmG80GsXdmzOVmYA2VRa1o4fKeZ6yMA24BsG9+4mAdmtfaCZFyyI04cqnEE23s/jq4rDHbEA/PnNk+y6D5sFXSTT01ble0zxL/yhml7NWq+WgyVem0ZycKk+klGk0I0j2PMfKIjT377HlzUe3Hj16FAe0PaApVXhGNIxuFppMhrYBd58wyTMNZ98zhZofXRBOb+YENFifLPrCMDXXtbvcxtqoN4Cv5PUGMKV+qmxz2zbCFkG+shANwCWmUPPoDtp+ttLeKkOGLP+emY4maOjCPeM1dElj2+xcc/dxtCsQovkotESz0wVhk9uH1jx7nG0yb4MrB8BtrG0eP5tUBrIL3Mba5uhcoskcBrIHnBpaWF7NKss01qJ9ojCFmkNw69aX+0Dz+1IbaYiGnY7GJ6dj7pytoS36NKdeZLwGg9n2k/xmp9WtrU2B3/O8A8ypGTXbWK4t29wlZ3MNJqdmhEtOG5UGP3k+xwa0WneIyi6nhjZRTpPnlkeVZWpoaa9Z8Q99vrKPuWYx/3f5Nt6AVmiLLqdto91megO20xvQKTSnt6jlJM/1+ThM4ZITB4e/5EwpjVDJXXKGO6KJJWctZ8nJU5ZccmIGcJgJaP6d7/29o9mfjdE4RMhuCmS6NzduzDy/JoyJOWkA7TqOezLtQafTGfCXnI2E0vCpMmfJOVWGA06VQc6SE73/OLOuocqSG9D37vtM5fnQyqHdvacBT4FG0MCDfol29Ce/u/lpvtdsiYI+dprsumbE9GTWFsKugwUeGpyyUTmfVHIba+s7x+fjnsyEMnsSx3xj2kxYazPKog3oAODhNEO70xnK8nDvc83ToJHo98hwNgVSaM5fv3n3+ox29NXVC6f4XhN1b8aTeztnK20+fRIHq5x9EsdYyW3boEo/7t5kjlm0X2OPtzlDNJd3d/fa8/y0aEifnoJYjGb78fkbM9KAC5sS0Te5cw2uLLy4e7MmM+WXbPemF3dvjks6/PLmOrjxqRmJ8ku2e9ONz5UeK4MyvQGYBbgxmqu7h3ajPc7nh0YF27ZLBDTYnpUGUDCbp/jn1yR7MmcUaminZY4yjSZWZrbSUmjylcVzzSUYTNDYu4fg0PNFIziKo6jFaDAHmHW1jc3wUrU8NPXRTn09KFOoCZWDMoWa+sitN/wyhZrmKKg3YP+n2U4zNAPRjHudnt+FUCxDy54pkEaz8dndG3AzH01iAzrZG0AHZo1/ynn65HSq9LnK1BnQNDs7xxZqctBEyrPP4OR044tb8Pmt55oGEMv29Oz5NSk0Z64/efwZW94sj+b4uTpGFeYkjlw0I1TOsydx5KIZ7YRK9uTZHDSzlHtCs3v1zp39tKM/DZqhIJOOXoQGNrZvnrm5j2vUNEd+vV5fhxJeM4JmPX2uNB8N5s1UOV+MJlQ2+MqDfvkgogSuXXgu5xnYfvLp+W/3c/mgOiZIQaKxNgcNrejkKlNzDSpdSF8NgINmrDzLDX0HHY1ANEvh7Nek0RQUavLRzNfXj48azeKAFilLXaOGVRbs19TXT+YpDzgah57sLpa4slOqD20PaMKrmc+XQTNDmamhTZWF10PLVR5wNJrn9/7caKZWXUVwL2gcWei4eoXmIKIZ0i9fLHGNmgrN80azZBGBOL0KzcFDI4RQSpQ3KzTPP3nOaXaq0FRoKjQVmgpNhaZCU6F5XmiaM5UVmueLZi5GU6Rk0SSVqQGfY9HMVh5gNJqVsvEflT71/Z+S9r9/n7LTaZuimXsrab9opWyqrKWUC2nlFOJykVLKUb6eUU5xp+3erxL2byn7v7dT9sqzRlNZZZVVVllllVWWtpJXiyx6evFhmKuEFYvLH1Ys+eplr1h6gMx+uvfcG4+KPFuGZk4TXcEoFE8OZ89UTZXxsfPMUQqPdODMeDo05hhN8RhaMZpeoXhyuGKIdvLYeaY5hUc6cPbDQFMY0V5ENL2nQ9MvjYYJOiXDVHmllbvWn5jzAqKh31u0fxMm359Hv2Nntnnxj0bRSOoTv+oXfYuCZMf3s2z4AqYBRBk6hZGab6JudaZ/sSrPOozouCwOu6/NCEGSFX9hotGbqVTHwDVPkfIHX9Q6L6DTUHNMw5azNpRtE8dT6Rn4I8fsfiKOCPFhhjZGL92Kj2r3UwmSpJrxL1V8C33DnryIbbKuIrJKi3o5X+mYvemr93Qi0lcfTl5dfRF9ZrZJfdN29vNnSbLZL+2LWsdQyn41bK/MKIu9vl04+7zwppr7fCLsgajuFmsiEwfFGmrDpWLNi27ifrMEcy9lhuGzVqr7/xKmF8b2jaZ4qcFYeTTFVYfQXgo0xctDvu3Ja7xiydh4X3bNsZcBzb7Ln3t6XnlxSeUPLyOrrLLKKqussspebhMcfpGjODmS+BVOPe+ZDjfFldIHWcqpFaUOm/O+RfEHk66JHc20iJV5vLhko9ma4Uhq+mFD5X9BstBxVINklrSqaSYPYVqOJyhZ6GpyySUNue/bMnovaNU5a45FN54GuiIbRJIthVgyLRvrVpZWymgdWLNcwZItsjS0HNKTKZN+TklBN6jf+EuObAuC3beIKtOXsNIbaC4Ou97pEVt2iGVbomTb1F+knpmQKfR9KwNJlXvR+zbD9238cJwGh9LrizieKrF0myz1NYXY9CMrFaIR7I6FMsEhhjAkqmrp0eJdkPkR0vJ6OjHwhRynL4odySQmrUou+Ukn0zs4xqqkSWQomkQWZXwhQnfOU8B7Xl8QzPB9y0QzHXzfiFC2jBewY4Nv9MuQXPyzTVOWcBRMtWeGe8d6IRp8piYjwb7ZEQ2iq4Zp9gUa5/hzjSQQ0RUMYpmGhmONdyZFI6WrMXhYS1UlyTBtB/1G8kyTfjOQbXl6Ssa8b9G0+uZ4d7xkcefgGwYGYSj0hR7p64ag9TWVmPTxYjSmQyRDsvDjKgsyHU4tfGagL3GzA61Hq5U28YiqmbrUwbBHa6JDQUjWMD2JKIoq4edDFnukI9oCnc8ESU/2dND3LQt9PEpPsgXHHL9vmehPtcW+f/t/3N2fj7QwRLYAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![resnet.png](attachment:resnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, mode='finetune', pretrained=True):\n",
    "        \"\"\"\n",
    "        use the ResNet50 model from torchvision models.\n",
    "        \n",
    "        mode has two options:\n",
    "        1) linear: For this mode, we want to freeze ResNet50 features, then train a linear\n",
    "            classifier which takes the features before FC (fully connected layer).\n",
    "            Replace FC with the one takes in the features and output scores of size 7. (7 expressions)\n",
    "        2) finetune: Same as 1) linear, except that we do not need to freeze the featues and\n",
    "            can finetune on the pretrained resnet model.\n",
    "        \"\"\"\n",
    "        self.resnet = models.resnet50(pretrained=Treu)\n",
    "        \n",
    "        if mode == 'linear':\n",
    "            for name, param in self.resnet.named_parameters():\n",
    "                if param.requires_grad and 'fc' not in name:\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            num_features = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(num_features, 7)\n",
    "            \n",
    "        elif mode == 'finetune':\n",
    "            num_features = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(num_features, 7)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "    \n",
    "    def to(self, device):\n",
    "        return self.resnet.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Linear Classifier\n",
    "First, we started with a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model, optimizer, and criterion\n",
    "model = Resnet(mode='linear', pretrained=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters()\n",
    "    lr = 0.005,\n",
    "    momentum = 0.9\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the batch size and number of workers\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "\n",
    "model_name = \"linear1.pt\"\n",
    "try:\n",
    "    model.load_state_dict(torch.load(PATH + model_name))\n",
    "    # continue training for more epochs:\n",
    "    # train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=5)\n",
    "except:\n",
    "    train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10)\n",
    "torch.save(model.state_dict(), PATH + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10 epochs, we were able to get 40.39% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Fully finetune with same learning rate\n",
    "Then, we moved to finetuned models. <br>\n",
    "We began with the learning rate of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_finetune1 = Resnet(mode='finetune', pretrained=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    resnet_finetune1.parameters(),\n",
    "    lr = 0.01,\n",
    "    momentum = 0.9\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### Rest are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the finetuned ResNet50, we got a 61.49% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Fully finetune with different learning rates\n",
    "In ResNet50, lower layers typically learn low-level features such as edges and textures that are useful across a wide range of tasks, and therefore may require smaller updates to prevent overfitting. Meanwhile, higher layers may learn more task-specific features that require larger updates to improve performance. <br>\n",
    "\n",
    "Therefore, we set the learning rate 'fc' layer to 0.01, and 0.001 for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_finetune2 = Resnet(mode='finetune', pretrained=True)\n",
    "\n",
    "last_params, rest_params = [], []\n",
    "for name, param in resnet_finetune2.named_parameters():\n",
    "    if 'fc' i nname:\n",
    "        last_params.append(param)\n",
    "    else:\n",
    "        rest_params.append(param)\n",
    "        \n",
    "optimizer = torch.optim.SGD(\n",
    "    [\n",
    "        {\"params\": last_params, \"lr\": 0.01, \"momentum\": 0.9},\n",
    "        {\"params\": rest_params, \"lr\": 0.001, \"momentum\": 0.9}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we got a 64.30% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. Finetune with frozen layers\n",
    "Freezing some layers during fine-tuning can help to prevent overfitting and speed up the training process. When we finetune a pre-trained neural network, we typically want to retain the learned feature representations in the lower layers of the network, which are often more general and transferable across different tasks. By freezing these lower layers, we prevent their weights from being updated during finetuning, which helps to ensure that the model retains its learned feature represenations. This can be particularly important if we have a small amount of data available for the specific task we are finetuning for. <br>\n",
    "\n",
    "In particular, we set the last fc layer's lr to be 0.01, the first two layers's lrs to be 0, and the rest for 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_params, lower_params, rest_params = [], [], []\n",
    "\n",
    "for name, param in resnet_finetune3.named_parameters():\n",
    "    if 'fc' in name:\n",
    "        last_params.append(param)\n",
    "    elif 'layer1' in name or 'layer2' in name:\n",
    "        lower_params.append(param)\n",
    "    else:\n",
    "        rest_params.append(param)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    [\n",
    "        {\"params\": last_params, \"lr\": 0.01, \"momentum\": 0.9},\n",
    "        {\"params\": lower_params, \"lr\": 0, \"momentum\": 0.9},\n",
    "        {\"params\": rest_params, \"lr\": 0.001, \"momentum\": 0.9}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we got a 61.66% validation accuracy after 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5. Image Augmentation\n",
    "While testing our finetuned models with different learning rates, we observed severe overfittings. To prevent the model learning from the same training data over and over, we used image transformations to 'virtually augment' the dataset. (Instead of adding more images to our dataset, we added the first layer that transforms our images). <br>\n",
    "\n",
    "We tried different combinations of image transfomations, and we \n",
    "decided to use 'horizontal flip', 'random rotation' and 'random perspective' from torchvision.transforms package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "image_hflip = transforms.RandomHorizontalFlip(p=0.2) # p = probability\n",
    "image_rotate = transforms.RandomRotation((-5, 5)) # degree limits\n",
    "image_randomP = transforms.RandomPerspective(distortion_scale=0.1, p=0.25)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, mode='finetune', augmented=False, pretrained=True):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        use the resnet18 model from torchvision models. Remember to set pretrained as true\n",
    "        \n",
    "        mode has two options:\n",
    "        1) linear: For this mode, we want to freeze resnet18 feautres, then train a linear\n",
    "                    classifier which takes the features before FC (again we do not want the resnet18 FC).\n",
    "                    And then write our own FC layer: which takes in the features and \n",
    "                    output scores of size 7 (since we have 7 categories)\n",
    "        2) finetune: Same as 1) linear, except that we do not need to freeze the features and\n",
    "                    can finetune on the pretrained resnet model.\n",
    "        \"\"\"\n",
    "    \n",
    "            \n",
    "        self.augmented = augmented\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        if mode == 'linear':\n",
    "            for name, param in self.resnet.named_parameters():\n",
    "                if param.requires_grad and 'fc' not in name:\n",
    "                    param.requires_grad = False\n",
    "            \n",
    "            num_features = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(num_features, 7)\n",
    "\n",
    "        elif mode == 'finetune':\n",
    "            num_features = self.resnet.fc.in_features\n",
    "            self.resnet.fc = nn.Linear(num_features, 7)\n",
    "\n",
    "    # Here, we added a layer that transforms our images\n",
    "    def forward(self, x):\n",
    "        if self.augmented:\n",
    "            x = image_hflip(x)\n",
    "            x = image_rotate(x)\n",
    "            x = image_randomP(x)\n",
    "        \n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "    def to(self, device):\n",
    "        return self.resnet.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried this image augmentation with the last two models (different learning rates and the one with frozen layers), and were able to achieve a 65.51% validation accuracy after 20 epochs with the model with different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
